\subsection{Functions and Predicates}

\marginnote{
    In general ``logical" means common to all instances and ``nonlogical" means unique to particular instance.
}

There are two types of concepts which appear in mathematical axiom systems.
These are (1) \df{logical concepts}, which are common to all axiom systems and (2) \df{nonlogical concepts}, which are the remaining concepts.

Informally, a \df{set} or \df{class} is a collection of objects.
If $A$ and $B$ are sets, a \df{mapping from $A$ to $B$} is an assignment of an object in $B$ to each object in $A$.
If $F$ designates the mapping, and $F$ assigns the element $b$ of $B$ to the element $a$ of $A$, we say that $b$ is the \df{value} of $F$ for the \df{argument} $a$, and write $F(a)$ for $b$.
An \df{$n$-tuple} in $A$ is a sequence of $n$ objects in $A$.
We write $(a_1, a_2, \ldots, a_n)$ for the $n$-tuple consisting of the objects $a_1, a_2, \ldots, a_n$ in that order.
A mapping from the set of $n$-tuples in $A$ to $B$ is called an \df{$n$-ary function from $A$ to $B$}.
A subset of the set of $n$-tuples in $A$ is called an \df{$n$-ary predicate in $A$}.
If $P$ represents such a predicate, then $P(a_1, \ldots, a_n)$ means that the $n$-tuple $(a_1, \ldots, a_n)$ is in $P$.
A unary function from $A$ to $B$ is a mapping from $A$ to $B$, and a unary predicate in $A$ is a subset of $A$.

There is exactly one 0-tuple in $A$, notated ( ).
A 0-ary function from $A$ to $B$ is simply an element of $B$.

\marginnote{
    The set of individuals of an axiom system makes up the universe of the system.
    Modern axiom systems have many universes in mind.
}

A mathematical axiom system has a certain set of objects called the \df{universe} of the axiom system, and its elements are called the \df{individuals} of the system.
Functions from the universe to the universe are called \df{individual functions}; predicates in the universe are called \df{individual predicates}.
We need symbols for certain individuals, individual functions, and individual predicates.

In any set $A$, we can form the binary predicate which consists of all 2-tuples whose first and second elements are the same element in $A$.
This is the \df{equality predicate} in $A$.
We shall use = to designate the equality predicate in the universe.

In a modern axiom system, we have several universes in mind.
For example, in the theory of fields, the possible universes are the various fields.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Truth Function}

\marginnote{
    Standard intro to truth functions.
}

We select two objects \T{} and \F{} and call them \df{truth values}.
We assign \T{} to each true formula and \F{} to each false formula.

We introduce the symbol \& to mean \df{and}.
The truth value of \A{} \& \B{} is determined by the truth values of \A{} and \B{}, not by what \A{} and \B{} mean.

A \df{truth function} is a function from the set of truth values to the set of truth values.
There is a binary truth function $H_\&$ such that if $a$ and $b$ are the truth values of \A{} and \B{} respectively, then $H_\&(a,b)$ is the truth value of \A{} \& \B{}
This function is described by the equations
\begin{align}
    H_\&(\T,\T) &= \T\,, \\
    H_\&(\T,\F) &= H_\&(\F,\T) = H_\&(\F,\F)\,.
\end{align}

We introduce the symbol $\vee$ to mean \df{or}.
We take \A{} $\vee$ \B{} to be false only if \A{} and \B{} are both false:
\begin{align}
    H_\vee(\T,\T) &= H_\vee(\T,\F) = H_\vee(\F,\T) = \T\,, \\
    H_\vee(\F,\F) &= \F\,.
\end{align}

We introduce $\ra$ to mean \emph{if \dots then}, so \A{} $\ra$ \B{} means \emph{if \A{} then \B{}}.
We regard \A{} $\ra$ \B{} to be false only when \A{} is true and \B{} is false:
\begin{align}
    H_\ra(\T,\T) &= H_\ra(\F,\T) = H_\ra(\F,\F) = \T\,, \\
    H_\ra(\T,\F) &= \F\,.
\end{align}

We introduce $\lra$ to mean \emph{if and only if}. \A{} $\lra$ \B{} is true if \A{} and \B{} are both true or both false:
\begin{align}
    H_\lra(\T,\T) &= H_\lra(\F,\F) = \T\,, \\
    H_\lra(\T,\F) &= H_\lra(\F,\T) = \F\,.
\end{align}

We introduce $\neg$ to mean \emph{not}.
$H_\neg$ is the unary truth function defined by
\begin{equation}
    H_\neg(\T) = \F\,, \quad H_\neg(\F) = \T\,.
\end{equation}

Some symbols can be defined in terms of others.
For example, \A $\ra$ \B{} means that either \A{} is false of \B{} is true.
That is, it means the same as $\neg \A{} \vee \B{}$.
More formally, if $a$ and $b$ are the truth values of \A{} and \B{}, then the truth value of \A $\ra$ \B{} is $H_\ra(a,b)$ and the truth value of $\neg \A{} \vee \B{}$ is $H_\vee(H_\neg(a),b)$.
But for every $a$ and $b$
\begin{equation}
    H_\ra(a,b) = H_\vee(H_\neg(a),b)\,.
\end{equation}

In the same way, we see that \A{} \& \B{} means the same as $\neg(\A{} \ra \neg \B{})$ and that $\A{} \lra \B{}$ means the same as $(\A{} \ra \B{})$ \& $(\B{} \ra \A{})$.
One can show that every symbol having a truth function associated with it in the above manner can be defined in terms of $\neg$ and $\vee$ (Problem 1).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Variables and Quantifiers}

\marginnote{
    Individual variables vary through individuals.
}

We cannot express yet a general law such as: \emph{every natural number is equal to itself}.
So we introduce \df{individual variables} (which we'll just call variables), which vary through the individuals.
As variables we use the symbols $x$, $y$, $z$, and $w$, adding primes to form new variables when needed.

\marginnote{
    Standard intro to quantifiers.
}

We introduce the symbol $\forall$, which means \emph{for all individuals}.
For example, $\forall x (x = 0)$ means \emph{for all natural numbers $x$, $x = 0$}.
This formula has only one meaning, while $x = 0$ has many.

We call the occurrence of $x$ in $x = 0$ a \df{free} occurrence, and we call the occurrences of $x$ in $\forall x (x = 0)$ \df{bound} occurrences.

We now introduce the symbol $\exists$ to mean \emph{there exists an individual $x$ such that};
e.g., $\exists x(x = 0)$ means \emph{there exists a natural number $x$ such that $x = 0$}.
The occurrences of $x$ in $\exists x (x = 0)$ are bound.

We may define $\forall$ in terms of $\exists$.
We define $\forall x \A{}$ to mean $\neg \exists x \neg \A{}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{First-Order Languages}
\begin{shaded*}
\marginnote{
    A first-order language is defined to be a language that has these symbols as well as formulas described below.
}

    A \df{first-order language} has as symbols the following:
    \begin{enumerate}
        \item the variables
            \begin{equation}
                x,y,z,w,x',y',z',w',x'',\dots\,;
            \end{equation}
        \item for each $n$, the $n$-ary function symbols and the $n$-ary predicate symbols;
        \item the symbols $\neg$, $\vee$, and $\exists$\,.
    \end{enumerate}
\end{shaded*}

\begin{remark}
    Among the binary predicate symbols must be the equality symbol =.
\end{remark}

A 0-ary function symbol is called a \df{constant}.
A function symbol or a predicate symbol other than = is called a \df{nonlogical} symbol;
other symbols are called \df{logical} symbols.

\marginnote{
    Some notation conventions.
}

If we change our notation by writing $\vee \A{}\B{}$ instead of $\A{} \vee \B{}$, we do not need to include parentheses and commas to indicate grouping.

We use \x{}, \y{}, \z{}, and \w{}, as syntactical variables which vary through variables;
\f{} and \g{} as syntactical variables which vary through function symbols;
\p{} and \q{} as syntactical variables which vary through predicate symbols;
and \e{} as a syntactical variable which varies through constants.

\begin{shaded*}
\marginnote{
    Terms are expressions which designate individuals.
}

We define the \df{terms} by the generalized inductive definition:
    \begin{enumerate}
        \item[(i)] a variable is a term;
        \item[(ii)] if $\bu{}_1, \dots, \bu{}_n$ are terms and \f{} is $n$-ary, then $\f{}\bu{}_1 \dots \bu{}_n$ is a term.
    \end{enumerate}
\end{shaded*}

We use \ba{}, \bb{}, \bc{}, and \bd{} as syntactical variables which vary through terms.

\begin{shaded*}
\marginnote{
    You can't add a symbol to the right of a formula to get a new formula.
}
    An \df{atomic formula} is an expression of the form $\p{}\ba{}_1\dots \ba{}_n$ where \p{} is $n$-ary.
    We define the \df{formulas} by the generalized inductive definition:
    \begin{enumerate}
        \item[(i)] an atomic formula is a formula;
        \item[(ii)] if \bu{} is a formula, then $\neg \bu{}$ is a formula;
        \item[(iii)] if \bu{} and \bv{} are formulas, then $\vee \bu{}\bv{}$ is a formula;
        \item[(iv)] if \bu{} is a formula, then $\exists \x{} \bu{}$ is a formula.
    \end{enumerate}
\end{shaded*}

\begin{remark}
    ``Corresponding to these two generalized inductive definitions we have forms of proof by induction.
    However, it is usually simpler to use induction on the length of the term or formula.
    Sometimes we use induction on the height of a formula, where the \df{height} is defined to be the number of occurrences of $\neg$, $\vee$, and $\exists$ in the formula."
\end{remark}

A \df{first-order language} is now defined to be a language in which the symbols and formulas are as described above.
A first-order language is thus completely determined by its nonlogical symbols.

\marginnote{
    The empty sequence is not a designator.
}

A \df{designator} is an expression which is either a term or a formula.
So every designator has the form $\bu{}\bv{}_1 \dots \bv{}_n$ where \bu{} is a symbol, $\bv{}_1$, \dots, $\bv{}_n$ are designators, and $n$ is a natural number determined by \bu{}.
We call $n$ the index of \bu{};
e.g., if \bu{} is $\exists$ then $n = 2$.

Two expressions are \df{compatible} if one of them can be obtained by adding some expression to the right end of the other.
If \bu{}\bv{} and $\bu{}'\bv{}'$ are compatible, then \bu{} and $\bu{}'$ are compatible;
i.e., if the expressions do not start with the same expression then adding an expression to the end of one will never result in the same expression as the other.
Similarly, if \bu{}\bv{} and $\bu{}\bv{}'$ are compatible, then \bv{} and $\bv{}'$ are compatible.

\begin{lemma}\label{compatibility lemma}
\marginnote{
    If we have two sequences of terms of equal length that are compatible, then they must be equal.
}
    If $\bu{}_1, \dots, \bu{}_n, \bu{}_1', \dots, \bu{}_n'$ are designators and $\bu{}_1 \dots \bu{}_n$ and $\bu{}_1' \dots \bu{}_n'$ are compatible, then $\bu{}_i$ is $\bu{}_i'$ for $i = 1,\dots,n$.
\end{lemma}

\begin{proof}
    Let $\bu{}_1, \dots, \bu{}_n$ and $\bu{}_1', \dots \bu{}_n'$ be designators such that $\bu{}_1 \dots \bu{}_n$ and $\bu{}_1' \dots \bu{}_n'$ are compatible.
    We use induction on the length of $\bu{}_1 \dots \bu{}_n$.
    Recall that the length of $\bu{}_1 \dots \bu{}_n$ is the number of occurrences of symbols in $\bu{}_1 \dots \bu{}_n$, not how many $\bu{}_i$ there are.
    
    Let the length of $\bu{}_1 \dots \bu{}_n$ be 1.
    Then $n = 1$ and we have that $\bu{}_1$ and $\bu{}_1'$ are compatible.
    Since the length of $\bu{}_1$ is 1, it is either a variable or constant.
    Then $\bu{}_1'$ begins with this variable or constant.
    But then $\bu{}_1'$ must only be this variable or constant since adding symbols to the right of a variable or constant results in an expression which is not a designator.
    Thus, $\bu{}_1$ is $\bu{}_1'$
    
    Now let the length of $\bu{}_1 \dots \bu{}_n$ be arbitrary and suppose the lemma holds for any lesser length.
    We write $\bu{}_1$ as $\bv{} \bv{}_1 \dots \bv{}_k$, where \bv{} is a symbol of index $k$ and $\bv{}_1, \dots, \bv{}_k$ are designators.
    Since $\bu{}_1 \dots \bu{}_n$ and $\bu{}_1' \dots \bu{}_n'$ are compatible, then $\bu{}_1'$ also starts with \bv{} and so we write $\bu{}_1'$ as $\bv{} \bv{}_1' \dots \bv{}_k'$, where $\bv{}_1', \dots, \bv{}_k'$ are designators.
    But since $\bu{}_1$ and $\bu{}_1'$ are compatible, then $\bv{}_1 \dots \bv{}_k$ and $\bv{}_1' \dots \bv{}_k'$ are compatible.
    By the inductive hypothesis, we have $\bv{}_i$ is $\bv{}_i'$ for $i = 1, \dots, k$.
    Thus $\bu{}_1$ is $\bu{}_1'$.
    Therefore, $\bu{}_2 \dots \bu{}_n$ and $\bu{}_2' \dots \bu{}_n'$ are compatible.
    By the induction hypothesis, we have $\bu{}_i$ is $\bu{}_i'$ for $i = 2, \dots, n$.
\end{proof}

\begin{theorem}[Formation Theorem]
\marginnote{
    In a first-order language, commas and parentheses are not necessary to determine grouping.
}
    Every designator can be written in the form $\bu{} \bv{}_1 \dots \bv{}_n$, where \bu{} is a symbol of index $n$ and $\bv{}_1 \dots \bv{}_n$ are designators, in one and only one way.
\end{theorem}

\begin{proof}
    We need only prove that it can be done in only one way.
    Now \bu{} must be the first symbol of the designator;
    so \bu{} and $n$ are uniquely determined.
    Thus it remains to show that if $\bu{} \bv{}_1 \dots \bv{}_n$ is the same as $\bu{} \bv{}_1' \dots \bv{}_n'$, where $\bv{}_1, \dots, \bv{}_n$ and $\bv{}_1', \dots, \bv{}_n'$ are designators, then $\bv{}_i$ is $\bv{}_i'$ for $i = 1, \dots, n$.
    If they are the same, then they are compatible, and so this follows from Lemma \ref{compatibility lemma}.
\end{proof}

\begin{lemma}\label{occurrence lemma}
    Every occurrence of a symbol in a designator \bu{} begins an occurrence of a designator in \bu{}.
\end{lemma}

\begin{proof}
    We use induction on the length of \bu{}.
    If the length of \bu{} is 1, then \bu{} is simply a variable or a constant, which are designators.
    
    Let the length of \bu{} be arbitrary.
    Write \bu{} as $\bv{} \bv{}_1 \dots \bv{}_k$, where \bv{} is a symbol of index $k$ and $\bv{}_1, \dots, \bv{}_k$ are designators.
    If the occurrence of a symbol in question is the initial \bv{}, then it begins \bu{}.
    Otherwise, the occurrence is in some $\bv{}_i$, and hence, by induction hypothesis, begins an occurrence of a designator in $\bv{}_i$.
    Hence it begins an occurrence of a designator in \bu{}.
\end{proof}

\begin{theorem}[Occurrence Theorem]\label{occurrence theorem}
\marginnote{
    The occurrence of a designator in $\bu{} \bv{}_1 \dots \bv{}_n$ does not start in one symbol and end in another.
}
    Let \bu{} be a symbol of index $n$, and let $\bv{}_1, \dots, \bv{}_n$ be designators.
    Then any occurrence of a designator \bv{} in $\bu{} \bv{}_1 \dots \bv{}_n$ is either all of $\bu{} \bv{}_1 \dots \bv{}_n$ or a part of one of the $\bv{}_i$.
\end{theorem}

\begin{proof}
    Suppose that the initial symbol of the occurrence of \bv{} is the initial \bu{} of $\bu{} \bv{}_1 \dots \bv{}_n$.
    Then \bv{} is $\bu{} \bv{}_1' \dots \bv{}_n'$ where $\bv{}_1', \dots, \bv{}_n'$ are designators.
    Since \bv{} is compatible with $\bu{} \bv{}_1 \dots \bv{}_n$, $\bv{}_1' \dots \bv{}_n'$ is compatible with $\bv{}_1 \dots \bv{}_n$.
    By Lemma \eqref{compatibility lemma}, $\bv{}_i$ is $\bv{}_i'$ for $i = 1, \dots, n$;
    so \bv{} is all of $\bu{} \bv{}_1 \dots \bv{}_n$.
    
    Now suppose that the initial symbol of the occurrence of \bv{} is within $\bv{}_i$.
    This symbol begins an occurrence of a designator $\bv{}'$ in $\bv{}_i$ by Lemma \eqref{occurrence lemma}.
    Clearly \bv{} and $\bv{}'$ are compatible;
    so by Lemma \eqref{compatibility lemma} \bv{} is $\bv{}'$.
    Hence \bv{} is a part of $\bv{}_i$.
\end{proof}

An occurrence of \x{} in \A{} is \df{bound in} \A{} if it occurs in a part of \A{} of the form $\exists \x{} \B{}$;
otherwise, it is \df{free in} \A{}.
We say that \x{} is \df{free} (\df{bound}) \df{in} \A{} if some occurrence of \x{} is free (bound) in \A{}.

\begin{remark}
    Note that \x{} may be both free and bound in \A{}.
    For example, if \A{} is $\f{} \x{} \exists \x{} \B{}$ then the first occurrence of \x{} is free in \A{} and the second occurrence of \x{} is bound in \A{}.
\end{remark}

It follows from the occurrence theorem (Theorem \eqref{occurrence theorem}) that if \y{} is distinct from \x{}, then the free occurrences of \x{} in $\neg \A{}$, $\vee \A{} \B{}$, and $\exists \y{} \A{}$ are just the free occurrences of \x{} in \A{} and \B{}.

We use $\bb{}_\x{} [\ba{}]$ to designate the expression obtained from \bb{} by replacing each occurrence of \x{} by \ba{};
and we use $\subst$ to designate the expression obtained from \A{} by replacing each free occurrence of \x{} by \ba{}.

\marginnote{
    We want $\subst$ to say the same thing about $\ba{}$ that $\A{}$ says about $\x{}$.
    So we restrict what is allowed to be substituted in for $\x{}$.
}

Let us consider the relationship between what $\subst$ says about \ba{} and what \A{} says about \x{}.
For example, suppose that \A{} is $\exists y (x = 2 * y)$, \x{} is $x$, and \ba{} is $y + 1$.
Then $\subst$ is $\exists y (y + 1 = 2 * y)$.
So \A{} says that $x$ is even;
but $\subst$ does not say that $y + 1$ is even.
It says rather that there exists a $y$ for which $y + 1 = 2 * y$.
So in general, $\subst$ does not say the same thing about the individual designated by \ba{} that \A{} says about the individual designated by \x{}.
The reason for this in this example is that the $y$ in the substituted $y + 1$ has become bound.
We wish to exclude such possibilities.

We say that \ba{} is \df{substitutible for} \x{} \df{in} \A{} if for each variable \y{} occurring in \ba{}, no part of \A{} of the form $\exists \y{} \B{}$ contains an occurrence of \x{} which is free in \A{}.
We now agree that whenever $\subst$ appears, \A{}, \x{}, and \ba{} are restricted to represent expressions such that \ba{} is substitutible for \ba{} in \A{}.
This avoids the problem in the previous example, and so $\subst$ will always say the same thing about the individual designated by \ba{} that \A{} says about the individual designated by \x{}.

We now extend this notion to several variables.
We let $\bb{}_{\x{}_1, \dots, \x{}_n} [\ba{}_1, \dots, \ba{}_n]$ designate the term obtained from \bb{} by replacing all occurrences of $\x{}_1, \dots, \x{}_n$ by $\ba{}_1, \dots, \ba{}_n$ respectively;
and we let $\A{}_{\x{}_1, \dots, \x{}_n} [\ba{}_1, \dots, \ba{}_n]$ designate the formula obtained from \A{} by replacing all free occurrences of $\x{}_1, \dots, \x{}_n$ by $\ba{}_1, \dots, \ba{}_n$ respectively.
Whenever $\A{}_{\x{}_1, \dots, \x{}_n} [\ba{}_1, \dots, \ba{}_n]$ appears, \A{}, $\x{}_1, \dots, \x{}_n$, $\ba{}_1, \dots, \ba{}_n$ are restricted to represent expressions such that $\ba{}_i$ is substitutible for $\x{}_i$ in \A{} for $i = 1, \dots, n$.

\marginnote{
    Defining symbols to include conventional notation.
    Omitting or adding parentheses for readability is fine.
}

We introduce the following defined symbols:
\begin{itemize}
    \item $(\A{} \vee \B{})$ is an abbreviation of $\vee \A{} \B{}$;
    \item $(\A{} \ra \B{})$ is an abbreviation of $(\neg \A{} \vee \B{})$;
    \item $(\A{} \& \B{})$ is an abbreviation of $\neg (\A \ra \neg \B{})$;
    \item $(\A{} \lra \B{})$ is an abbreviation of $((\A{} \ra \B{}) \& (\B{} \ra \A{}))$;
    \item $\forall \x{} \A{}$ is an abbreviation of and $\neg \exists \x{} \neg \A{}$.
    \item If \bu{} is a binary predicate or function symbol, then $(\ba{} \bu{} \bb{})$ is an abbreviation of $\bu{} \ba{} \bb{}$;
    \item if \bu{} is a binary predicate symbol, then $(\ba{} \cancel{\bu{}} \bb{})$ is an abbreviation of $\neg (\ba{} \bu{} \bb{})$.
\end{itemize}

\begin{remark}
    We agree that a formula shall be of the form $\A{} \& \B{}$ or $\A{} \lra \B{}$ rather than $\A{} \vee \B{}$ or $\A \& \B{}$ whenever there is a choice.
    
    We adopt the convention of \df{association to the right} for omitting parentheses.
    Thus $\A{} \vee \B{} \vee \C{} \vee \D{}$ is read $\A{} \vee (\B{} \vee (\C{} \vee \D{}))$, and so on.
\end{remark}

\newpage
We call:
    \begin{itemize}
        \item $\neg \A{}$ the \df{negation} of \A{};
        \item $\A{} \vee \B{}$ the \df{disjunction} of \A{} and \B{};
        \item $\A{} \& \B{}$ the \df{conjunction} of \A{} and \B{};
        \item $\A{} \ra \B{}$ the \df{implication} of \B{} by \A{};
        \item $\A{} \lra \B{}$ the \df{equivalence} of \A{} and \B{};
        \item $\exists \x{} \A{}$ the \df{instantiation} of \A{} by \x{};
        \item $\forall \x{} \A{}$ the \df{generalization} of \A{} by \x{}; and
        \item the expressions $\exists \x{}$ and $\forall \x{}$ \df{quantifiers on} \x{}.
    \end{itemize}

\begin{remark}
        We call $\exists \x{}$ an \df{existential} quantifier and $\forall \x{}$ a \df{universal} quantifier.
\end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Structures}

\begin{shaded*}
\marginnote{
    Individuals of $\msa{}$ are given names.
    Add names to $L$ to get $L(\msa{})$.
    Assign every variable-free term of $L(\msa{})$ to an individual of $\msa{}$.
    Closed formulas of $L(\msa{})$ are given truth values specifying if they are true or not in $\msa{}$.
    We are then able to say $\A{}$ is valid in $\msa{}$ if every instantiation $\A{} [\bi{}_1 \dots \bi{}_n]$ is true in $\msa{}$.
}
    Let $L$ be a first-order language.
    A \df{structure} $\msa{}$ for $L$ consists of the following things:
    \begin{enumerate}
        \item[(i)] A nonempty set $|\msa{}|$, called the \df{universe} of $\msa{}$.
            The elements of $|\msa{}|$ are called the \df{individuals} of $\msa$.
        \item[(ii)] For each $n$-ary function symbol \f{} of $L$, an $n$-ary fuction $\f{}_\msa{}$ from $|\msa{}|$ to $|\msa{}|$.
            (In particular, for each constant $\e{}$ of $L$, $\e{}_\msa{}$ is an individual of $\msa{}$.)
        \item[(iii)] For each $n$-ary predicate symbol $\p{}$ of $L$ other than =, an $n$-ary predicate $\p{}_\msa{}$ in $|\msa{}|$.
    \end{enumerate}
\end{shaded*}

Structures are a precise description of the semantics of first-order languages.

We want to define a formula \A{} to be valid in $\msa{}$ if all the meanings of \A{} are true in $\msa{}$.
Thus we want for each meaning of \A{} a formula which expressed exactly that meaning.
Since a meaning of \A{} is obtained by assigning an individual as meaning to each variable free in \A{}, we want names for the individuals.

For each individual $a$ of $\msa{}$, we choose a new constant, called the \df{name} of $a$.
The first-order language obtained from $L$ by adding all the names of individuals of $\msa{}$ is designated by $L(\msa{})$.
We use \bi{} and \bj{} as syntactical variables which vary through names.

An expression is \df{variable-free} if it contains no variables.
We define an individual $\msa{}(\ba{})$ of $\msa{}$ for each variable-free term \ba{} of $L(\msa{})$.
The definition is by induction on the length of \ba{}.
If \ba{} is a name, $\msa{}(\ba{})$ is the individual of which \ba{} is the name.
If \ba{} is not a name, then it must be $\f{} \ba{}_1 \dots \ba{}_n$ with \f{} a function symbol of $L$.
We then let $\msa{}(\ba{})$ be $\f{}_\msa{} (\msa{}(\ba{}_1), \dots, \msa{}(\ba{}_n))$.

A formula \A{} is \df{closed} if no variable is free in \A{}.
We define a truth value $\msa{}(\A{})$ for each closed formula \A{} in $L(\msa{})$.
The definition is by induction on the length of \A{}.
If \A{} is $\ba{} = \bb{}$, then \ba{} and \bb{} must be variable-free since \A{} is closed.
We let $\msa{}(\A{}) = \T{}$ iff $\msa{}(\ba{})$ and $\msa{}(\bb{})$ are the same.
If \A{} is $\p{} \ba{}_1 \dots \ba{}_n$, where \p{} is not =, we let $\msa{}(\A{}) = \T{}$ iff the $n$-tuple $(\msa{}(\ba{}_1), \dots, \msa{} (\ba{}_n))$ belongs to the predicate $\p{}_\msa{}$.
If \A{} is $\neg \B{}$, then $\msa{}(\A{})$ is $H_\neg (\msa{}(\B{})$.
If \A{} is $\B{} \vee \C{}$, then $\msa{}$ is $H_\vee (\msa{}(\B{}), \msa{}(\C{}))$.
If \A{} is $\exists \x{} \B{}$, then $\msa{} (\A{}) = \T{}$ iff $\msa{} (\B{}_\x{} [\bi{}]) = \T{}$ for some \bi{} in $L(\msa{})$.

We have:
\begin{itemize}
    \item $\msa{} (\A{} \ra \B{}) = H_\ra (\msa{}(\A{}), \msa{}(\B{}))$;
    \item $\msa{}(\A{} \& \B{}) = H_\& (\msa{}(\A{}), \msa{}(\B{}))$;
    \item $\msa{}(\A{} \lra \B{}) = H_\lra (\msa{}(\A{}), \msa{}(\B{}))$;
    \item $\msa{}(\A{}_1 \vee \dots \vee \A{}_n) = \T{}$ iff $\msa{}(A{}_i) = \T{}$ for at least one $i$;
    \item $\msa{}(\A{}_1 \& \dots \& \A{}_n) = \T{}$ iff $\msa{}(\A{}_i) = \T{}$ for all $i$; and
    \item $\msa{}(\forall \x{} \A{}) = \T{}$ iff $\msa{} (\substi) = \T{}$ for every \bi{} in $L(\msa{})$.
\end{itemize}

If \A{} is a formula of $L$, an $\msa{}$-\df{instance} of \A{} is a closed formula of the form $\A{}[\bi{}_1, \dots, \bi{}_n]$ in $L(\msa{})$.
A formula is \df{valid} in $\msa{}$ if $\msa{} (\A{}') = \T{}$ for every $\msa{}$-instance $\A{}'$ of \A{}.

\begin{lemma}\label{substitution lemma}
\marginnote{
    Says $\bb{}_\x [\ba{}]$ and $\subst$ have the proper meaning.
}
    Let $\msa{}$ be a structure for $L$;
    \ba{} a variable-free term in $L(\msa{})$;
    \bi{} the name of $\msa{}(\ba{})$.
    If \bb{} is a term of $L(\msa{})$ in which no variable except \x{} occurs, then $\msa{} (\bb{}_\x{}[\ba{}]) = \msa{} (\bb{}_\x{}[\bi{}])$.
    If \A{} is a formula of $L(\msa{})$ in which no variable except \x{} is free, then $\msa{} (\A{}_\x{}[\ba{}]) = \msa{} (\A{}_\x{}[\bi{}])$.
\end{lemma}

\begin{proof}
    We prove the first conclusion by induction on the length of \bb{}.
    Let the length of \bb{} be one.
    If \bb{} is a name, then $\bb{}_\x{} [\ba{}]$ and $\bb{}_\x [\bi{}]$ are both \bb{};
    so the conclusion is evident.
    If \bb{} is a variable, it must be \x{};
    so $\bb{}_\x{} [\ba{}]$ is \ba{} and $\bb{}_\x{} [\bi{}]$ is \bi{}.
    But $\msa{}(\ba{}) = \msa{}(\bi{})$ by the choice of \bi{}.
    
    Now let the length of \bb{} be arbitrary and suppose that the first conclusion holds for any lesser length.
    Then \bb{} is $\f{} \bb{}_1 \dots \bb{}_n$ with \f{} a function symbol of $L$, then, using the induction hypothesis, we have
    \begin{align}
        \msa{}(\bb{}[\ba{}]) &=
            \msa{}(\f{}\bb{}_1[\ba{}] \dots \bb{}_n[\ba{}]) \\
            &= \f_\msa{} (\msa{} (\bb{}_1 [\ba{}]), \dots, \msa{} (\bb{}_n [\ba{}])) \\
            &= \f_\msa{} (\msa{} (\bb{}_1 [\bi{}]), \dots, \msa{} (\bb{}_n [\bi{}])) \\
            &= \msa{}(\f{}\bb{}_1[\bi{}] \dots \bb{}_n[\bi{}]) \\
            &= \msa{} (\bb{}[\bi{}])\,.
    \end{align}
    
    We now prove the second conclusion by induction on the length of \A{}.
    If \A{} is $\bb{} = \bc{}$, then, using the first conclusion,
    \begin{align}
        \msa{}(\A{}[\ba]) = \T{}
            &\lra \msa{}(\bb{}[\ba{}]) = \msa{}(\bc{}[\ba{}]) \\
            &\lra \msa{}(\bb{}[\bi{}]) = \msa{}(\bc{}[\bi{}]) \\
            &\lra \msa{}(\A{}[\bi{}]) = \T{}\,.
    \end{align}
    If \A{} is $\p{} \bb{}_1 \dots \bb{}_n$ where \p{} is not =, the proof is quite similar.
    If \A{} if $\neg \B{}$, then
    \begin{align}
        \msa{}(\A{}[\ba{}])
            &= H_\neg (\msa{} (\B{}[\ba{}])) \\
            &= H_\neg (\msa{} (\B{}[\bi{}])) \\
            &= \msa{} (\A{}[\bi{}])\,.
    \end{align}
    If \A{} is $\B{} \vee \C{}$, the proof is similar.
    Now suppose that \A{} is $\exists \y{} \B{}$.
    We may suppose that \y{} is not \x{}, since otherwise $\A{}_\x{}[\ba{}]$ and $\A{}_\x{}[\bi{}]$ are both \A{}.
    Then
    \begin{align}
        \msa{}(\A{}_\x{}[\ba{}]) = \T{}
            &\lra \msa{}(\exists \y{} \B{}_\x{} [\ba{}]) = \T{} \\
            &\lra \msa{}(\B{}_{\x{},\y{}} [\ba{}, \bj{}]) = \T{} \quad \text{for some \bj{}} \\
            &\lra \msa{}(\B{}_{\x{},\y{}} [\bi{}, \bj{}]) = \T{} \quad \text{for some \bj{}} \\
            &\lra \msa{}(\exists \y{} \B{}_\x{} [\bi{}]) = \T{} \\
            &\lra \msa{} (\A{}_\x{}[\bi{}]) = \T{}\,.
    \end{align}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Logical Axioms and Rules}

\marginnote{
    In order to ensure that all of the theorems of a formal system are valid in $\msa{}$,
    we require that the axioms be valid and that the rules be such that the validity of the conclusion follows from the validity of the hypotheses.
}

\df{Logically valid} formulas of $L$ are valid simply because of the meaning of the logical symbols;
i.e., they are valid in every structure for $L$.
\df{Logical axioms} are logically valid axioms.
The others, called \df{nonlogical axioms}, will be valid because of particular properties of the structure $\msa{}$.

We say that \A{} is a \df{logical consequence} of a set $\Gamma$ of formulas if it is a consequence of $\Gamma$ because of the meaning of the logical symbols;
i.e., if \A{} is valid in every structure for $L$ in which all of the formulas in $\Gamma$ are valid.
We don't have logical and nonlogical rules because we can always add things as axioms.

Let $L$ be a first-order language. We have:
\begin{itemize}
    \item A \df{propositional axiom} is a formula of the form $\propax$\,;
    \item A \df{substitution axiom} is a formula of the form $\subax$\,;
    \item An \df{identity axiom} is a formula of the form $\idax$\,;
    \item An \df{equality axiom} is a formula of the form \[\eqax\] or of the form \[\eqpredax\]\,.
\end{itemize}
A \df{logical axiom} is a formula which is either a propositional axiom, a substitution axiom, an identity axiom, or an equality axiom.

We now show that the logical axioms are valid.
Let $\msa{}$ be a structure for $L$.
An $\msa{}$-instance of a propositional axiom has the form $\propax$; and
\[\msa{}(\neg \A{} \vee \A{}) = H_\vee (H_\neg (\msa{}(\A{})), \msa{} (\A{})) = \T{}\,.\]
An $\msa{}$-instance of a substitution axiom has the form $\subax$.
Suppose that $\msa{} (\subax) = \F{}$.
Then $\msa{} (\subst) = \T{}$ and $\msa{} (\exists \x{} \A{}) = \F{}$.
If \bi{} is the name of $\msa{} (\ba{})$, the latter implies that $\msa{} (\substi) = \F{}$ while the former with Lemma \eqref{substitution lemma} implies that $\msa{} (\substi) = \T{}$.
This is a contradiction.
An $\msa{}$-instance of an identity axiom has the form $\bi{} = \bi{}$;
since $\msa{} (\bi{}) = \msa{} (\bi{})$, then $\msa{} (\bi{} = \bi{}) = \T{}$.
An $\msa{}$-instance of an equality axiom has the form
\[\bi{}_1 = \bj{}_1 \ra \dots \ra \bi{}_n = \bj{}_n \ra \f{} \bi{}_1 \dots \bi{}_n = \f{} \bj{}_1 \dots \bj{}_n\,.\]
We have
\begin{align*}
    \msa{} (\bi{}_1 &= \bj{}_1 \ra \dots \ra \bi{}_n = \bj{}_n \ra \f{} \bi{}_1 \dots \bi{}_n = \f{} \bj{}_1 \dots \bj{}_n)\\
        &= H_\ra (\msa{} (\bi{}_1 = \bj{}_1 \ra \dots \ra \bi{}_n = \bj{}_n),\\
            &\qquad \msa{} (\f{} \bi{}_1 \dots \bi{}_n = \f{} \bj{}_1 \dots \bj{}_n))\\
        &= H_\ra (\msa{} (\bi{}_1 = \bj{}_1 \ra \dots \ra \bi{}_n = \bj{}_n),\\
            &\qquad \f{}_\msa{} (\msa{} (\bi{}_1), \dots, \msa{} (\bi{}_n)) = \f{}_\msa{} (\msa{} (\bj{}_1), \dots, \msa{} (\bj{}_n)))\\
        &= \T{}\,.
\end{align*}
The proof for the predicate form of the equality axiom is similar.

We now introduce five rules of inference:
\begin{itemize}
    \item \df{Expansion Rule.} Infer $\B{} \vee \A{}$ from \A{}\,;
    \item \df{Contraction Rule.} Infer \A{} from $\A{} \vee \A{}$\,;
    \item \df{Associative Rule.} Infer $(\A{} \vee \B{}) \vee \C{}$ from $\A{} \vee (\B{} \vee \C{})$\,;
    \item \df{Cut Rule.} Infer $\B{} \vee \C{}$ from $\A{} \vee \B{}$ and $\neg \A{} \vee \C{}$\,;
    \item \df{$\exists$-Introduction Rule.} If \x{} is not free in \B{}, infer $\exists \x{} \A{} \ra \B{}$ from $\A{} \ra \B{}$\,.
\end{itemize}

\begin{remark}
    Note that these rules are finite.
\end{remark}

We now wish to see that the conclusion of each rule is a logical consequence of the hypotheses of the rule.

We show this first for the Expansion Rule.
Suppose \A{} is valid in $\msa{}$.
Let $\B{}' \vee \A{}'$ be an $\msa{}$-instance of $\B{} \vee \A{}$.
We want to show that $\msa{} (\B{}' \vee \A{}') = \T{}$.
Since \A{} is valid in $\msa{}$ then $\msa{} (\A{}') = \T{}$, and so $\msa{} (\B{}' \vee \A{}') = \T{}$.

We now show this for the Contraction Rule.
Suppose $\A{} \vee \A{}$ is valid in $\msa{}$.
Let $\A{}'$ be an $\msa{}$-instance of $\A{}$.
We want to show that $\msa{} (\A{}') = \T{}$.
Since $\A{} \vee \A{}$ is valid in $\msa{}$ then $\msa{} (\A{}' \vee \A{}') = \T{}$, and so $\msa{} (\A{}') = \T{}$.

We now show this for the Associative Rule.
Suppose $\A{} \vee (\B{} \vee \C{})$ is valid in $\msa{}$.
Let $(\A{}' \vee \B{}') \vee \C{}'$ be an $\msa{}$-instance of $(\A{} \vee \B{}) \vee \C{}$.
We want to show that $\msa{} ((\A{}' \vee \B{}') \vee \C{}') = \T{}$.
Since $\A{} \vee (\B{} \vee \C{})$ is valid in $\msa{}$, then $\msa{} (\A{}' \vee (\B{}' \vee \C{}')) = \T{}$.
This means that either $\msa{} (\A{}') = \T{}$ or $\msa{} (\B{}' \vee \C{}') = \T{}$.
In either case, $\msa{} ((\A{}' \vee \B{}') \vee \C{}') = \T{}$.

We now show this for the Cut Rule.
Suppose that $\A{} \vee \B{}$ and $\neg \A{} \vee \C{}$ are valid in $\msa{}$.
Let $\B{}' \vee \C{}'$ be an $\msa{}$-instance of $\B{} \vee \C{}$.
We want to show that $\msa{} (\B{}' \vee \C{}') = \T{}$.
Since $\A{} \vee \B{}$ is valid in $\msa{}$ then $\msa{} (\A{}' \vee \B{}') = \T{}$. Similarly, $\msa{} (\neg \A{}' \vee \C{}') = \T{}$.
If $\msa{} (\A{}') = \F{}$ then $\msa{} (\B{}') = \T{}$, and so $\msa{} (\B{}' \vee \C{}') = \T{}$.
If $\msa{} (\A{}') = \F{}$ then $\msa{} (\C{}') = \T{}$, and so $\msa{} (\B{}' \vee \C{}') = \T{}$.

We now show this for the $\exists$-Introduction Rule.
Suppose that $\A{} \ra \B{}$ is valid in $\msa{}$ and that \x{} is not free in \B{}.
Let $\exists \x{} \A{}' \ra \B{}'$ be an $\msa{}$-instance of $\exists \x{} \A{} \ra \B{}$.
We want to show that $\msa{} (\exists \x{} \A{}' \ra \B{}') = \T{}$.
Suppose that $\msa{} (\exists \x{} \A{}' \ra \B{}') = \F{}$.
Then $\msa{} (\exists \x{} \A{}') = \T{}$ and $\msa{} (\B{}') = \F{}$.
From the former, $\msa{} (\A{}'_\x{} [\bi{}]) = \T{}$ for some $\bi{}$;
so $\msa{} (\A{}'_\x{} [\bi{}] \ra \B{}') = \F{}$.
This is a contradiction, since $\A{}'_\x{} [\bi{}] \ra \B{}'$ is an $\msa{}$-instance of the valid formula $\A{} \ra \B{}$.
Thus, $\msa{} (\exists \x{} \A{}' \ra \B{}') = \T{}$.

\begin{shaded*}
\marginnote{
    This is the class of formal systems we will study.
}
    A \df{first-order theory}, or simply a \df{theory}, is a formal system $T$ such that
    \begin{enumerate}
        \item[(i)] the language of $T$ is a first-order language;
        \item[(ii)] the axioms of $T$ are the logical axioms of $L(T)$ and certain further axioms, called the nonlogical axioms;
        \item[(iii)] the rules of $T$ are the expansion rule, the contraction rule, the associative rule, the cut rule, and the $\exists$-introduction rule.
    \end{enumerate}
\end{shaded*}

\begin{remark}
    In order to specify a theory then, we only have to specify its nonlogical symbols and its nonlogical axioms.
\end{remark}

\begin{example}[Elementary Theory of Groups]
    The elementary theory of groups, designated by $G$ has only one nonlogical symbol, which is the binary function symbol $\cdot$.
    The nonlogical axioms of $G$ are:
    \begin{itemize}
        \item[G1.] $(x \cdot y) \cdot z = x \cdot (y \cdot z)$\,;
        \item[G2.] $\exists x (\forall y (x \cdot y = y) \& \forall y \exists z (z \cdot y = x))$\,.
    \end{itemize}
\end{example}

By a \df{model} of a theory $T$, we mean a structure for $L(T)$ in which all the nonlogical axioms of $T$ are valid.
A formula is \df{valid in $T$} if it is valid in every model of $T$;
equivalently, if it is a logical consequence of the nonlogical axioms of $T$.

\begin{example}
    The set of $2 \cross 2$ matrices under matrix multiplication is a structure for $G$;
    however, it is not a model of $G$.
    The set of invertible $2 \cross 2$ matrices under matrix multiplication is a model for $G$.
\end{example}

\begin{theorem}[Validity Theorem]\label{validity theorem}
    If $T$ is a theory, then every theorem of $T$ is valid in $T$.
\end{theorem}

\begin{proof}
    We use induction on theorems.
    If \A{} is a nonlogical axiom, the result is true by the definition of a model.
    If \A{} is a logical axiom, the result was proved above.
    If \A{} is the conclusion of a rule, the result follows from the induction hypothesis and the facts proved above.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Problems}

\begin{exercise}
    asdf
\end{exercise}

\begin{exercise}
    jkl;
\end{exercise}

\begin{exercise}
    Show that if \bu{}\bv{} and \bv{}\bv{}' are designators, then either \bv{} or \bv{}' is the empty expression.
\end{exercise}

\begin{proof}
    Let $\bu{} \bv{}$ and $\bv{} \bv{}'$ be arbitrary designators.
    Suppose that \bv{} is nonempty.
    Write $\bv{}\bv{}'$ as $\bv{}'' \bv{}_1 \dots \bv{}_k$, where $\bv{}''$ is a $k$-ary symbol and $\bv{}_1, \dots, \bv{}_k$ are designators.
    Then \bv{} starts with $\bv{}''$.
    It must be that \bv{} is a designator, otherwise $\bu{} \bv{}$ would not be a designator.
    Thus \bv{} is all of $\bv{}'' \bv{}_1 \dots \bv{}_k$ and $\bv{}'$ is the empty expression.
    
    Now suppose $\bv{}'$ is nonempty.
    If $\bv{}'$ is all of $\bv{}'' \bv{}_1 \dots \bv{}_k$, then we are done.
    So suppose that $\bv{}'$ is not all of $\bv{}'' \bv{}_1 \dots \bv{}_k$.
    Then \bv{} is nonempty.
    But we've already shown that if \bv{} is nonempty, then $\bv{}'$ is the empty expression, which is a contradiction.
    Thus, $\bv{}'$ is all of $\bv{}'' \bv{}_1 \dots \bv{}_k$ and \bv{} is the empty expression.
\end{proof}
